{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b8a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import riva.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b5ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import io\n",
    "import IPython.display as ipd\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1724b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "riva_asr = riva.client.ASRService(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e57df474",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE = 'harvard.wav'\n",
    "with wave.open(AUDIO_FILE, \"rb\") as wav:\n",
    "    audio = wav.readframes(wav.getnframes())\n",
    "# ipd.Audio(audio, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "badd3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = riva.client.RecognitionConfig(\n",
    "    encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"vi-VN\",  \n",
    "    max_alternatives=1,\n",
    "    enable_automatic_punctuation=True,\n",
    "    audio_channel_count = 1   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b287d390",
   "metadata": {},
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Error: Unavailable model requested given these parameters: language_code=vi; sample_rate=16000; type=offline; \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:50051 {created_time:\"2025-11-12T18:27:47.3852327+00:00\", grpc_status:3, grpc_message:\"Error: Unavailable model requested given these parameters: language_code=vi; sample_rate=16000; type=offline; \"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m riva_asr\u001b[38;5;241m.\u001b[39moffline_recognize(audio, config)\n\u001b[0;32m      2\u001b[0m asr_best_transcript \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39malternatives[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtranscript\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mASR Transcript:\u001b[39m\u001b[38;5;124m\"\u001b[39m, asr_best_transcript)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\riva\\client\\asr.py:485\u001b[0m, in \u001b[0;36mASRService.offline_recognize\u001b[1;34m(self, audio_bytes, config, future)\u001b[0m\n\u001b[0;32m    483\u001b[0m request \u001b[38;5;241m=\u001b[39m rasr\u001b[38;5;241m.\u001b[39mRecognizeRequest(config\u001b[38;5;241m=\u001b[39mconfig, audio\u001b[38;5;241m=\u001b[39maudio_bytes)\n\u001b[0;32m    484\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub\u001b[38;5;241m.\u001b[39mRecognize\u001b[38;5;241m.\u001b[39mfuture \u001b[38;5;28;01mif\u001b[39;00m future \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub\u001b[38;5;241m.\u001b[39mRecognize\n\u001b[1;32m--> 485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(request, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mget_auth_metadata())\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1175\u001b[0m     (\n\u001b[0;32m   1176\u001b[0m         state,\n\u001b[0;32m   1177\u001b[0m         call,\n\u001b[0;32m   1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m     )\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39mresponse\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Error: Unavailable model requested given these parameters: language_code=vi; sample_rate=16000; type=offline; \"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B::1%5D:50051 {created_time:\"2025-11-12T18:27:47.3852327+00:00\", grpc_status:3, grpc_message:\"Error: Unavailable model requested given these parameters: language_code=vi; sample_rate=16000; type=offline; \"}\"\n>"
     ]
    }
   ],
   "source": [
    "response = riva_asr.offline_recognize(audio, config)\n",
    "asr_best_transcript = response.results[0].alternatives[0].transcript\n",
    "print(\"ASR Transcript:\", asr_best_transcript)\n",
    "\n",
    "print(\"\\n\\nFull Response Message:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7609662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ASRService.streaming_response_generator() got an unexpected keyword argument 'end_of_stream'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m audio_bytes[i:i\u001b[38;5;241m+\u001b[39mchunk_size]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# G·ªçi inference\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m responses \u001b[38;5;241m=\u001b[39m riva_asr\u001b[38;5;241m.\u001b[39mstreaming_response_generator(\n\u001b[0;32m     34\u001b[0m     audio_chunks(audio_bytes),\n\u001b[0;32m     35\u001b[0m     config,\n\u001b[0;32m     36\u001b[0m     end_of_stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# ‚ö†Ô∏è b√°o audio ƒë√£ h·∫øt\u001b[39;00m\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n",
      "\u001b[1;31mTypeError\u001b[0m: ASRService.streaming_response_generator() got an unexpected keyword argument 'end_of_stream'"
     ]
    }
   ],
   "source": [
    "import riva.client\n",
    "from riva.client import ASRService\n",
    "import wave\n",
    "\n",
    "# ƒê·ªãa ch·ªâ server\n",
    "RIVA_SERVER = \"localhost:50051\"\n",
    "\n",
    "# K·∫øt n·ªëi Riva\n",
    "auth = riva.client.Auth(uri=RIVA_SERVER)\n",
    "riva_asr = ASRService(auth)\n",
    "\n",
    "# File √¢m thanh test (16kHz, mono, wav)\n",
    "AUDIO_FILE = \"harvard.wav\"\n",
    "\n",
    "with wave.open(AUDIO_FILE, \"rb\") as wav:\n",
    "    audio_bytes = wav.readframes(wav.getnframes())\n",
    "\n",
    "# C·∫•u h√¨nh ASR\n",
    "config = riva.client.RecognitionConfig(\n",
    "    encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"vi-VN\",\n",
    "    max_alternatives=1,\n",
    "    enable_automatic_punctuation=True,\n",
    "    verbatim_transcripts=False\n",
    ")\n",
    "print(\"üó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\")\n",
    "def audio_chunks(audio_bytes, chunk_size=4000):\n",
    "    for i in range(0, len(audio_bytes), chunk_size):\n",
    "        yield audio_bytes[i:i+chunk_size]\n",
    "\n",
    "# G·ªçi inference\n",
    "responses = riva_asr.streaming_response_generator(\n",
    "    audio_chunks(audio_bytes),\n",
    "    config,\n",
    "    end_of_stream=True  # ‚ö†Ô∏è b√°o audio ƒë√£ h·∫øt\n",
    ")\n",
    "print(\"üó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\")\n",
    "for response in responses:\n",
    "    for result in response.results:\n",
    "        if len(result.alternatives) > 0:\n",
    "            print(\"Transcript:\", result.alternatives[0].transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c4e476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import riva.client\n",
    "from riva.client import ASRService\n",
    "\n",
    "# K·∫øt n·ªëi server\n",
    "RIVA_SERVER = \"localhost:50051\"\n",
    "auth = riva.client.Auth(uri=RIVA_SERVER)\n",
    "riva_asr = ASRService(auth)\n",
    "\n",
    "# ƒê·ªçc file WAV 16kHz mono\n",
    "AUDIO_FILE = \"harvard.wav\"\n",
    "with wave.open(AUDIO_FILE, \"rb\") as wav:\n",
    "    audio_bytes = wav.readframes(wav.getnframes())\n",
    "\n",
    "# Generator chia chunk v√† b√°o end-of-stream\n",
    "def audio_chunks(audio_bytes, chunk_size=4000):\n",
    "    for i in range(0, len(audio_bytes), chunk_size):\n",
    "        yield audio_bytes[i:i+chunk_size]\n",
    "    yield b\"\"  # ‚ö†Ô∏è k·∫øt th√∫c streaming\n",
    "\n",
    "# C·∫•u h√¨nh ASR\n",
    "config = riva.client.RecognitionConfig(\n",
    "    encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"vi-VN\",\n",
    "    max_alternatives=1,\n",
    "    enable_automatic_punctuation=True,\n",
    "    verbatim_transcripts=False\n",
    ")\n",
    "\n",
    "# G·ªçi streaming inference\n",
    "responses = riva_asr.streaming_response_generator(audio_chunks(audio_bytes), config)\n",
    "\n",
    "print(\"üó£Ô∏è  K·∫øt qu·∫£ nh·∫≠n d·∫°ng:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8ae529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ASRService.streaming_response_generator at 0x0000022A94CD2110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cba176",
   "metadata": {},
   "outputs": [
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception iterating requests!\"\n\tdebug_error_string = \"None\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m responses \u001b[38;5;241m=\u001b[39m riva_asr\u001b[38;5;241m.\u001b[39mstreaming_response_generator(audio_chunks(audio_bytes), config)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Ki·ªÉm tra output\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresults:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m alt \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39malternatives:\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\riva\\client\\asr.py:443\u001b[0m, in \u001b[0;36mASRService.streaming_response_generator\u001b[1;34m(self, audio_chunks, streaming_config)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03mGenerates speech recognition responses for fragments of speech audio in :param:`audio_chunks`.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;124;03mThe purpose of the method is to perform speech recognition \"online\" - as soon as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    <https://docs.nvidia.com/deeplearning/riva/user-guide/docs/reference/protos/protos.html#riva-proto-riva-asr-proto>`_.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m generator \u001b[38;5;241m=\u001b[39m streaming_request_generator(audio_chunks, streaming_config)\n\u001b[1;32m--> 443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub\u001b[38;5;241m.\u001b[39mStreamingRecognize(generator, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mget_auth_metadata()):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\grpc\\_channel.py:969\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception iterating requests!\"\n\tdebug_error_string = \"None\"\n>"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "from riva.client import ASRService, RecognitionConfig, AudioEncoding, Auth\n",
    "\n",
    "# K·∫øt n·ªëi server\n",
    "auth = Auth(uri=\"localhost:50051\")\n",
    "riva_asr = ASRService(auth)\n",
    "\n",
    "# ƒê·ªçc audio\n",
    "AUDIO_FILE = \"harvard.wav\"\n",
    "with wave.open(AUDIO_FILE, \"rb\") as wav:\n",
    "    audio_bytes = wav.readframes(wav.getnframes())\n",
    "\n",
    "# Generator cho streaming\n",
    "def audio_chunks(audio_bytes, chunk_size=4000):\n",
    "    for i in range(0, len(audio_bytes), chunk_size):\n",
    "        yield audio_bytes[i:i+chunk_size]\n",
    "\n",
    "# C·∫•u h√¨nh ASR\n",
    "config = RecognitionConfig(\n",
    "    encoding=AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code=\"vi-VN\",\n",
    "    max_alternatives=1,\n",
    "    enable_automatic_punctuation=True,\n",
    "    verbatim_transcripts=False\n",
    ")\n",
    "\n",
    "# Streaming inference\n",
    "responses = riva_asr.streaming_response_generator(audio_chunks(audio_bytes), config)\n",
    "\n",
    "# Ki·ªÉm tra output\n",
    "for response in responses:\n",
    "    for result in response.results:\n",
    "        for alt in result.alternatives:\n",
    "            transcript = alt.transcript\n",
    "            speaker = getattr(alt, \"speaker_tag\", None)\n",
    "            if speaker:\n",
    "                print(f\"[Speaker {speaker}]: {transcript}\")\n",
    "            else:\n",
    "                print(f\"[Transcript]: {transcript}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5fae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
